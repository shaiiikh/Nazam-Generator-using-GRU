{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQz7mIRrwoak"
      },
      "source": [
        "#Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shaiiikh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.0436 - loss: 6.9751\n",
            "Epoch 2/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.0623 - loss: 6.4712\n",
            "Epoch 3/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.0948 - loss: 6.1006\n",
            "Epoch 4/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.1187 - loss: 5.7179\n",
            "Epoch 5/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.1414 - loss: 5.3380\n",
            "Epoch 6/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.1640 - loss: 4.9707\n",
            "Epoch 7/30\n",
            "2842/2842 - 21s - 7ms/step - accuracy: 0.1959 - loss: 4.6172\n",
            "Epoch 8/30\n",
            "2842/2842 - 21s - 7ms/step - accuracy: 0.2330 - loss: 4.2805\n",
            "Epoch 9/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.2779 - loss: 3.9607\n",
            "Epoch 10/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.3232 - loss: 3.6605\n",
            "Epoch 11/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.3655 - loss: 3.3806\n",
            "Epoch 12/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.4056 - loss: 3.1263\n",
            "Epoch 13/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.4455 - loss: 2.8984\n",
            "Epoch 14/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.4796 - loss: 2.6939\n",
            "Epoch 15/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.5083 - loss: 2.5118\n",
            "Epoch 16/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.5386 - loss: 2.3474\n",
            "Epoch 17/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.5631 - loss: 2.2029\n",
            "Epoch 18/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.5880 - loss: 2.0721\n",
            "Epoch 19/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.6085 - loss: 1.9545\n",
            "Epoch 20/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6287 - loss: 1.8489\n",
            "Epoch 21/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6458 - loss: 1.7509\n",
            "Epoch 22/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6620 - loss: 1.6665\n",
            "Epoch 23/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6778 - loss: 1.5863\n",
            "Epoch 24/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6892 - loss: 1.5167\n",
            "Epoch 25/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.7035 - loss: 1.4478\n",
            "Epoch 26/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.7136 - loss: 1.3875\n",
            "Epoch 27/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.7235 - loss: 1.3348\n",
            "Epoch 28/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.7348 - loss: 1.2821\n",
            "Epoch 29/30\n",
            "2842/2842 - 26s - 9ms/step - accuracy: 0.7417 - loss: 1.2362\n",
            "Epoch 30/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.7497 - loss: 1.1930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "2025-02-08 22:17:14.289 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.463 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run c:\\Users\\shaiiikh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
            "2025-02-08 22:17:14.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.467 Session state does not function when running a script without `streamlit run`\n",
            "2025-02-08 22:17:14.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# Dataset Loading (Using first 700 entries)\n",
        "poetry_data = pd.read_csv(\"roman urdu poetry.csv\").iloc[:700]\n",
        "poetry_lines = poetry_data[\"Poetry\"].dropna().tolist()\n",
        "\n",
        "# Text Processing\n",
        "combined_text = \" \".join(poetry_lines)\n",
        "all_words = combined_text.split()\n",
        "\n",
        "# Encoding words\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(all_words)\n",
        "\n",
        "word_to_idx = {word: idx for idx, word in enumerate(encoder.classes_)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Creating sequences\n",
        "sequence_data = []\n",
        "for i in range(len(all_words) - 5):\n",
        "    sequence_data.append([word_to_idx[word] for word in all_words[i: i + 6]])\n",
        "\n",
        "sequence_data = np.array(sequence_data)\n",
        "X, y = sequence_data[:, :-1], sequence_data[:, -1]\n",
        "\n",
        "# Model Building\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word_to_idx), output_dim=50, input_length=X.shape[1]),\n",
        "    GRU(100, return_sequences=False),\n",
        "    Dense(len(word_to_idx), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "model.fit(X, y, epochs=30, verbose=2)\n",
        "\n",
        "# Saving the Model\n",
        "model.save(\"poetry_gru_model.h5\")\n",
        "with open(\"word_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoder, f)\n",
        "\n",
        "# Streamlit Interface\n",
        "st.title(\"Roman Urdu Nazam Generator\")\n",
        "user_input = st.text_input(\"Start your Nazam:\")\n",
        "\n",
        "if st.button(\"Generate\"):\n",
        "    input_words = user_input.split()\n",
        "    for _ in range(20):  # Generate 20 additional words\n",
        "        input_seq = [word_to_idx.get(word, 0) for word in input_words[-5:]]\n",
        "        input_seq_padded = pad_sequences([input_seq], maxlen=5)\n",
        "        predicted_idx = np.argmax(model.predict(input_seq_padded), axis=-1)[0]\n",
        "        next_word = idx_to_word[predicted_idx]\n",
        "        input_words.append(next_word)\n",
        "\n",
        "    st.write(\" \".join(input_words))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
